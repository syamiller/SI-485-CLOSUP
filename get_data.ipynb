{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "nD_hxK2ZM6Mj",
      "metadata": {
        "id": "nD_hxK2ZM6Mj"
      },
      "source": [
        "## XBRL US API - ACFR statements by report  \n",
        "\n",
        "### Authenticate for access token\n",
        "Click in the gray code cell below, then click the Run button above to execute the cell. Type your XBRL US Web account email, account password, Client ID, and secret as noted, pressing the Enter key on the keyboard after each entry.\n",
        "\n",
        "XBRL US limits records returned for a query to improve efficiency; this script loops to collect all data from the Public Filings Database for a query. **Non-members might not be able to return all data for a query** - join XBRL US for comprehensive access - https://xbrl.us/join."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "uLT1UeHGM6Mk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLT1UeHGM6Mk",
        "outputId": "9caede5e-0b28-4a38-8eba-39e97ee2051b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your XBRL US Web account email: \n",
            "\n",
            "\n",
            "Your access token expires in 60 minutes. After it expires, run the cell immediately below this one to generate a new token and continue to use the query cell. \n",
            "\n",
            "For now, skip ahead to the section 'Make a Query'.\n"
          ]
        }
      ],
      "source": [
        "print('Enter your XBRL US Web account email: ')\n",
        "import os, re, sys, json\n",
        "import requests\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "import getpass\n",
        "from datetime import datetime\n",
        "import urllib\n",
        "from urllib.parse import urlencode\n",
        "email = input()\n",
        "password = getpass.getpass(prompt='Password: ')\n",
        "clientid = getpass.getpass(prompt='Client ID: ')\n",
        "secret = getpass.getpass(prompt='Secret: ')\n",
        "\n",
        "body_auth = {'username' : ''.join(email),\n",
        "            'client_id': ''.join(clientid),\n",
        "            'client_secret' : ''.join(secret),\n",
        "            'password' : ''.join(password),\n",
        "            'grant_type' : 'password',\n",
        "            'platform' : 'ipynb' }\n",
        "\n",
        "payload = urlencode(body_auth)\n",
        "url = 'https://api.xbrl.us/oauth2/token'\n",
        "headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "\n",
        "res = requests.request(\"POST\", url, data=payload, headers=headers)\n",
        "auth_json = res.json()\n",
        "\n",
        "if 'error' in auth_json:\n",
        "    print (\"\\n\\nThere was a problem generating an access token with these credentials. Run the first cell again to enter credentials.\")\n",
        "else:\n",
        "    print (\"\\n\\nYour access token expires in 60 minutes. After it expires, run the cell immediately below this one to generate a new token and continue to use the query cell. \\n\\nFor now, skip ahead to the section 'Make a Query'.\")\n",
        "access_token = auth_json['access_token']\n",
        "refresh_token = auth_json['refresh_token']\n",
        "newaccess = ''\n",
        "newrefresh = ''\n",
        "#print('access token: ' + access_token + ' refresh token: ' + refresh_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ucp9M5qFM6Ml",
      "metadata": {
        "id": "Ucp9M5qFM6Ml"
      },
      "source": [
        "#### Refresh token\n",
        "The cell below is only needed to refresh an expired access token after 60 minutes. When the access token no longer returns results, run the cell below to refresh the access token or re-enter credentials by running the cell above. Until the refresh token process is needed, **skip ahead to _Make a Query_**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "nuEHdpV7M6Ml",
      "metadata": {
        "id": "nuEHdpV7M6Ml"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'newrefresh' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token \u001b[38;5;241m=\u001b[39m token \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnewrefresh\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m refresh_token\n\u001b[1;32m      3\u001b[0m refresh_auth \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(clientid),\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(secret),\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrant_type\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefresh_token\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplatform\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipynb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefresh_token\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(token) }\n\u001b[1;32m      8\u001b[0m refreshres \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, data\u001b[38;5;241m=\u001b[39mrefresh_auth)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'newrefresh' is not defined"
          ]
        }
      ],
      "source": [
        "token = token if newrefresh != '' else refresh_token\n",
        "\n",
        "refresh_auth = {'client_id': ''.join(clientid),\n",
        "            'client_secret' : ''.join(secret),\n",
        "            'grant_type' : 'refresh_token',\n",
        "            'platform' : 'ipynb',\n",
        "            'refresh_token' : ''.join(token) }\n",
        "refreshres = requests.post(url, data=refresh_auth)\n",
        "refresh_json = refreshres.json()\n",
        "access_token = refresh_json['access_token']\n",
        "refresh_token = refresh_json['refresh_token']#print('access token: ' + access_token + 'refresh token: ' + refresh_token)\n",
        "print('Your access token is refreshed for 60 minutes. If it expires again, run this cell to generate a new token and continue to use the query cells below.')\n",
        "print(access_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qc35WHGeM6Ml",
      "metadata": {
        "id": "Qc35WHGeM6Ml"
      },
      "source": [
        "### Make a query\n",
        "After the access token confirmation appears above, you can modify the query below and use the **_Cell >> Run_** menu option with the cell **immediately below this text** to run the query for updated results.\n",
        "\n",
        "The sample results are from a set of ACFR reports posted to the XBRL US Public Filings Database.  To test for results quickly, modify the **_report\\_ids_** to shorten the list, and change the **_XBRL\\_Elements_** to return different data from an ACFR statement.\n",
        "  \n",
        "Refer to XBRL API documentation at https://xbrlus.github.io/xbrl-api/#/Facts/getFactDetails for other endpoints and parameters to filter and return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "up to 5000 records are found so far ...\n",
            " - this set contained fewer than the 5000 possible, only 206 records.\n",
            "up to 5000 records are found so far ...\n",
            " - this set contained fewer than the 5000 possible, only 135 records.\n",
            "up to 5000 records are found so far ...\n",
            " - this set contained fewer than the 5000 possible, only 145 records.\n",
            "up to 5000 records are found so far ...\n",
            " - this set contained fewer than the 5000 possible, only 293 records.\n",
            "up to 5000 records are found so far ...\n",
            " - this set contained fewer than the 5000 possible, only 90 records.\n",
            "\n",
            "At Mon Apr 15 13:58:26 2024, the query finished with   869   rows returned in 0:00:09.351173 for \n",
            "https://api.xbrl.us/api/v1/cube/search?report.id=677268,677267&fields=report.id,period.fiscal-year,cube.description.sort(ASC),cube.tree-sequence.sort(ASC),report.entity-name,dimensions.count,dimension-pair,cube.primary-local-name,fact.value,unit&unique=&cube.description=200110\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import urllib.parse\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Define the parameters for the filter and fields to be returned,\n",
        "# run the loop to return results\n",
        "offset_value = 0\n",
        "res_df = []\n",
        "\n",
        "# Define which endpoint to use\n",
        "endpoint = 'cube' #taxonomy presentation linkbase + facts\n",
        "\n",
        "# Define the parameters of the query\n",
        "\n",
        "# statementIDs = [801150, 300000, 705000, 801100, 400000, 300690, 300691, 804000,\n",
        "#        200110, 709100, 404000, 805050, 704100, 700000, 100000, 300001,\n",
        "#        805000, 804050, 605000, 604000, 606000, 607000, 704000, 702000,\n",
        "#        601000, 600000, 602000, 501200, 502000, 501800, 603000, 803000,\n",
        "#        803050, 707000, 709000, 200060, 200300, 200050, 200000, 100700,\n",
        "#        100400, 100100, 100800, 101100, 200040, 300200, 500000, 500800,\n",
        "#        500600, 300600, 300500, 300745, 300740, 300710]\n",
        "\n",
        "statementIDs = [404000, 300690, 200000, 801150, 200110]\n",
        "\n",
        "# query for ACFR reports, sort by year descending and name ascending\n",
        "# https://api.xbrl.us/api/v1/report/search?report.source-name=ACFR&fields=report.entity-name,report.period-focus,report.year-focus,report.filing-date,report.id,report.entry-url,report.source-name\n",
        "\n",
        "report_ids = [\n",
        "    '677268',  # County of Ogemaw: https://xbrlus.github.io/acfr/ixviewer/ix.html?doc=../samples/100/Ogemaw-20210930-Annual-Accounts.htm\n",
        "    '677267'  # Flint, Michigan: https://xbrlus.github.io/acfr/ixviewer/ix.html?doc=../samples/107/FLINTF652021.htm\n",
        "    #'591765',  # William Rainey Harper College: https://xbrlus.github.io/acfr/ixviewer/ix.html?doc=../samples/106/HARPER2021.htm\n",
        "    #'591766',  # Oakton Community College: https://xbrlus.github.io/acfr/ixviewer/ix.html?doc=../samples/77/OAKTON2021.html\n",
        "    #'591767'  # College of DuPage: https://xbrlus.github.io/acfr/ixviewer/ix.html?doc=../samples/82/COD2021.htm\n",
        "]\n",
        "\n",
        "# query for unique Statements in the 2022 GRIP Taxonomy\n",
        "# https://api.xbrl.us/api/v1/dts/729592/network/search?network.link-name=presentationLink&fields=network.role-description.sort(ASC),dts.id&unique\n",
        "\n",
        "XBRL_Elements = [\n",
        "    str(x) for x in statementIDs\n",
        "]\n",
        "\n",
        "# Define data fields to return (multi-sort based on order)\n",
        "\n",
        "fields = [\n",
        "    # this is the list of the characteristics of the data being returned by the query\n",
        "    'report.id',\n",
        "    'period.fiscal-year',\n",
        "    'cube.description.sort(ASC)',\n",
        "    'cube.tree-sequence.sort(ASC)',\n",
        "    'report.entity-name',\n",
        "    'dimensions.count',\n",
        "    'dimension-pair',\n",
        "    'cube.primary-local-name',\n",
        "    'fact.value',\n",
        "    'unit'\n",
        "]\n",
        "\n",
        "params = {\n",
        "    # this is the list of what's being queried against the endpoint\n",
        "    'report.id': ','.join(report_ids),\n",
        "    'fields': ','.join(fields),\n",
        "    'unique': ''\n",
        "}\n",
        "\n",
        "# Create query and loop for all results - code below does not need to be changed\n",
        "search_endpoint = 'https://api.xbrl.us/api/v1/' + endpoint + '/search'\n",
        "orig_fields = params['fields']\n",
        "query_start = datetime.now()\n",
        "\n",
        "for xbrl_element in XBRL_Elements:\n",
        "    params['cube.description'] = xbrl_element\n",
        "    printed = False\n",
        "    while True:\n",
        "        if not printed:\n",
        "            printed = True\n",
        "        res = requests.get(search_endpoint, params=params, headers={'Authorization': 'Bearer {}'.format(access_token)})\n",
        "        res_json = res.json()\n",
        "        if 'error' in res_json:\n",
        "            print('There was an error: {}'.format(res_json['error_description']))\n",
        "            break\n",
        "\n",
        "        print(\"up to\", str(offset_value + res_json['paging']['limit']), \"records are found so far ...\")\n",
        "\n",
        "        res_df += res_json['data']\n",
        "\n",
        "        if res_json['paging']['count'] < res_json['paging']['limit']:\n",
        "            print(\" - this set contained fewer than the\", res_json['paging']['limit'], \"possible, only\",\n",
        "                  str(res_json['paging']['count']), \"records.\")\n",
        "            break\n",
        "        else:\n",
        "            offset_value += res_json['paging']['limit']\n",
        "            if 100 == res_json['paging']['limit']:\n",
        "                params['fields'] = orig_fields + ',' + endpoint + '.offset({})'.format(offset_value)\n",
        "                if offset_value == 10 * res_json['paging']['limit']:\n",
        "                    break\n",
        "            elif 500 == res_json['paging']['limit']:\n",
        "                params['fields'] = orig_fields + ',' + endpoint + '.offset({})'.format(offset_value)\n",
        "                if offset_value == 4 * res_json['paging']['limit']:\n",
        "                    break\n",
        "            params['fields'] = orig_fields + ',' + endpoint + '.offset({})'.format(offset_value)\n",
        "\n",
        "if not 'error' in res_json:\n",
        "    current_datetime = datetime.now().replace(microsecond=0)\n",
        "    time_taken = current_datetime - query_start\n",
        "    index = pd.DataFrame(res_df).index\n",
        "    total_rows = len(index)\n",
        "    your_limit = res_json['paging']['limit']\n",
        "    limit_message = \"If the results below match the limit noted above, you might not be seeing all rows, and should consider upgrading (https://xbrl.us/access-token).\\n\"\n",
        "\n",
        "    if your_limit == 100:\n",
        "        print(\"\\nThis non-Member account has a limit of \", 10 * your_limit,\n",
        "              \" rows per query from our Public Filings Database. \" + limit_message)\n",
        "    elif your_limit == 500:\n",
        "        print(\"\\nThis Basic Individual Member account has a limit of \", 4 * your_limit,\n",
        "              \" rows per query from our Public Filings Database. \" + limit_message)\n",
        "\n",
        "    print(\"\\nAt \" + current_datetime.strftime(\"%c\") + \", the query finished with  \", str(total_rows),\n",
        "          \"  rows returned in \" + str(time_taken) + \" for \\n\" + urllib.parse.unquote(res.url))\n",
        "\n",
        "    df = pd.DataFrame(res_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "76b712eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create separate column for cube id\n",
        "df['cube_id'] = df['cube.description'].apply(lambda x: x.split('-')[0].strip())\n",
        "\n",
        "\n",
        "df['fact.value'] = pd.to_numeric(df['fact.value'], errors='coerce')\n",
        "df = df[df['fact.value'].notna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('xbrl_data.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": ""
    },
    "kernelspec": {
      "display_name": "",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
